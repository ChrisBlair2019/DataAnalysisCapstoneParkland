{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K Means and General Cluster Analysis to Discover Subgroups in Discussion about Mental Health "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Import Statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import indicoio, json, re\n",
    "from urlextract import URLExtract\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from empath import Empath\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import plotly.plotly.plotly\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "lexicon = Empath()\n",
    "nltk.download('stopwords')\n",
    "import plotly.offline as plotoff \n",
    "plotoff.init_notebook_mode()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and URL extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_indico.json', 'r') as myfile:\n",
    "    data2 = json.loads(myfile.read())\n",
    "    \n",
    "extractor = URLExtract()\n",
    "\n",
    "timestamp = []\n",
    "sentiment = []\n",
    "political = []\n",
    "\n",
    "num = 0\n",
    "for x in data2['comments']:\n",
    "    num += 1\n",
    "    \n",
    "    # TEXT CLEANING\n",
    "    input_str = data2['comments'][x]['body'].lower() # all letters become lowercase \n",
    "    \n",
    "    url = extractor.find_urls(input_str)          # extracts and removes url\n",
    "    if(len(url) != 0):\n",
    "        input_str = input_str.replace(url[0],'')\n",
    "\n",
    "    input_str = re.sub(r'\\d+', '', input_str)     # removes numbers\n",
    "    input_str = input_str.strip()                 # removes whitespace\n",
    "    input_str = re.sub(r'[^\\w\\s]', '', input_str)   # removes punctuation\n",
    "    \n",
    "    \n",
    "    \n",
    "    # STORING THE TIMESTAMP, SENTIMENT, POLITICAL DATA IN SEPARATE LISTS\n",
    "    if( 'timestamp' in data2['comments'][x] and input_str):\n",
    "        timestamp.append(data2['comments'][x]['timestamp'])\n",
    "        #sentiment.append(indicoio.sentiment(input_str))\n",
    "        #political.append(indicoio.political(input_str))\n",
    "        \n",
    "    data2['comments'][x]['body'] = input_str\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting the Comments based on the LSA Model on Mental Health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15561\n"
     ]
    }
   ],
   "source": [
    "#SUBSETING COMMENTS \n",
    "subsetList = set()\n",
    "for x in data2[\"comments\"]:\n",
    "    if (\"mental\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"health\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"shoot\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"amend\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"nra\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"problem\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"illness\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"issue\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"firearm\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"mass\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"shooting\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"countries\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "    if (\"law\") in data2[\"comments\"][x][\"body\"]:\n",
    "        subsetList.add(x)\n",
    "print(len(subsetList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Sentiment and Political Affiliation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5908\n",
      "9616\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "DListPolAff = list()\n",
    "DListSentiment = list()\n",
    "RListPolAff = list()\n",
    "RListPolSentiment = list()\n",
    "Rcomments = list()\n",
    "Dcomments = list()\n",
    "DCount = 0\n",
    "RCount = 0\n",
    "ErrorCount = 0\n",
    "for x in subsetList:\n",
    "    try:\n",
    "        if data2[\"comments\"][x][\"pol_aff\"][\"Conservative\"] > data2[\"comments\"][x][\"pol_aff\"][\"Liberal\"]:\n",
    "            RListPolAff.append(data2[\"comments\"][x][\"pol_aff\"][\"Conservative\"])\n",
    "            ds = analyser.polarity_scores(data2[\"comments\"][x][\"body\"])\n",
    "            RListPolSentiment.append(ds[\"compound\"])\n",
    "            Rcomments.append(data2[\"comments\"][x][\"body\"])\n",
    "            RCount = RCount + 1\n",
    "        else:\n",
    "            DListPolAff.append(data2[\"comments\"][x][\"pol_aff\"][\"Liberal\"])\n",
    "            ds = analyser.polarity_scores(data2[\"comments\"][x][\"body\"])\n",
    "            DListSentiment.append(ds[\"compound\"])\n",
    "            Dcomments.append(data2[\"comments\"][x][\"body\"])\n",
    "            DCount = DCount + 1\n",
    "    except:\n",
    "        ErrorCount = ErrorCount + 1\n",
    "    \n",
    "print(DCount)\n",
    "print(RCount)\n",
    "print(ErrorCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a subset of the Political Affiliation to Understand how Republicans and Democrats are Distributed Spatially "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]\n",
      "[ (2,1) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Republican = go.Scatter(\n",
    "    x = RListPolAff[1:500],\n",
    "    mode = 'markers',\n",
    ")\n",
    "\n",
    "Democrat = go.Scatter(\n",
    "    x = DListPolAff[1:500],\n",
    "    mode = 'markers',\n",
    ")\n",
    "\n",
    "fig = plotly.tools.make_subplots(rows=2, cols=1)\n",
    "\n",
    "fig.append_trace(Republican, 1, 1)\n",
    "fig.append_trace(Democrat, 2, 1)\n",
    "\n",
    "plotoff.iplot({\n",
    "    \"data\": fig,\n",
    "    \"layout\": go.Layout(title=\"Republican Users Sentiment versus Democrat Users Sentiment\",\n",
    "                        xaxis=dict(\n",
    "        title='Republican Political Sentiment of the Comment',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Democrat Political Sentiment of the Comment',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    "                        )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cluster coherence in order to show significance of certain subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3116864065995788\n"
     ]
    }
   ],
   "source": [
    "# Adapted from https://plot.ly/scikit-learn/plot-kmeans-silhouette-analysis/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "n_cluster = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "silhouette_avg = []\n",
    "\n",
    "for n_clusters in n_cluster:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    reduced_data = PCA(n_components=2).fit_transform(df)\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_clusters,  n_init=10)\n",
    "    kmeans.fit(reduced_data)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_data)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg.append(silhouette_score(reduced_data, cluster_labels))\n",
    "    print(n_clusters)\n",
    "    \n",
    "    \n",
    "figure = go.Scatter(\n",
    "    x = n_cluster,\n",
    "    y = silhouette_avg,\n",
    "    mode = 'lines+markers')\n",
    "\n",
    "plotoff.iplot({\n",
    "    \"data\": [figure],\n",
    "    \"layout\": go.Layout(title=\"Number of Clusters vs. Silhouette Avg\",\n",
    "                        xaxis=dict(\n",
    "        title='Number of Clusters',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Silhouette Score',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    "                        )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clsutering using PCA Reduced Data in order to show Sub-Groups that arise within Discussion, Maximizing the Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-means clustering, adapted from tutorial from https://plot.ly/scikit-learn/plot-kmeans-digits/\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "subsetList = 0\n",
    "\n",
    "data2 = 0\n",
    "\n",
    "np.random.seed(seed=1000)\n",
    "\n",
    "choiceRand = np.random.rand(1500)\n",
    "\n",
    "subset1 = []\n",
    "\n",
    "subset2 = []\n",
    "\n",
    "for a in range(len(RListPolSentiment)):\n",
    "    if RListPolSentiment[a] > 0.05 or RListPolSentiment[a] < -0.05:\n",
    "        subset1.append(a)\n",
    "        \n",
    "for b in range(len(DListSentiment)):\n",
    "    if DListSentiment[b] > 0.05 or DListSentiment[b] < -0.05:\n",
    "        subset2.append(b)\n",
    "    \n",
    "\n",
    "\n",
    "randIndicesR = np.random.choice(subset1, 1500)\n",
    "RListPolSentimentRandomized = [RListPolSentiment[i] for i in randIndicesR]\n",
    "RCommentsRandomized = [Rcomments[i] for i in randIndicesR]\n",
    "\n",
    "randIndicesD = np.random.choice(subset2, 1500)\n",
    "DListPolSentimentRandomized = [DListSentiment[i] for i in randIndicesD]\n",
    "DCommentsRandomized = [DListSentiment[i] for i in randIndicesD]\n",
    "\n",
    "Data = {\"RSent\" : RListPolSentimentRandomized,\n",
    "        \"DSent\": DListPolSentimentRandomized,\n",
    "        \"RPolAff\": np.random.choice([RListPolAff[i] for i in randIndicesR], 1500),\n",
    "        \"DPolAff\": np.random.choice([DListPolAff[i] for i in randIndicesD], 1500)}\n",
    "\n",
    "df = DataFrame(Data, columns=['RSent','DSent', \"RPolAff\", \"DPolAff\"])\n",
    "\n",
    "def matplotlib_to_plotly(cmap, pl_entries):\n",
    "    h = 1.0/(pl_entries-1)\n",
    "    pl_colorscale = []\n",
    "    \n",
    "    for k in range(pl_entries):\n",
    "        C = list(map(np.uint8, np.array(cmap(k*h)[:3])*255))\n",
    "        pl_colorscale.append([k*h, 'rgb'+str((C[0], C[1], C[2]))])\n",
    "        \n",
    "    return pl_colorscale\n",
    "\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(df)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=4,  n_init=10)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "gc.collect()\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "back = go.Heatmap(x=xx[0][:len(Z)],\n",
    "                  y=xx[0][:len(Z)],\n",
    "                  z=Z,\n",
    "                  showscale=False,\n",
    "                  colorscale=matplotlib_to_plotly(plt.cm.Paired, len(Z)))\n",
    "\n",
    "markers = go.Scatter(x=reduced_data[:, 0], \n",
    "                     y=reduced_data[:, 1],\n",
    "                     showlegend=False,\n",
    "                     mode='markers', \n",
    "                     marker=dict(\n",
    "                             size=3, color='black'))\n",
    "\n",
    "# Plot the centroids as a white \n",
    "centroids = kmeans.cluster_centers_\n",
    "center = go.Scatter(x=centroids[:, 0],\n",
    "                    y=centroids[:, 1],\n",
    "                    showlegend=False,\n",
    "                    mode='markers', \n",
    "                    marker=dict(\n",
    "                            size=10, color='white'))\n",
    "data=[back, markers, center]\n",
    "\n",
    "layout = go.Layout(title ='K-means clustering with Sentiment (PCA-reduced data)<br>'\n",
    "                           'On Subsetted dataset relating to Mental Health',\n",
    "                   xaxis=dict(ticks='', showticklabels=False,\n",
    "                              zeroline=False, title='2-D Sentiment (-1 to 1)'),\n",
    "                   yaxis=dict(ticks='', showticklabels=False,\n",
    "                              zeroline=False))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotoff.iplot(fig, auto_open=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all of the Comments with their class Labels, to show Class Labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "Repub\n",
      "Democrat\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(kmeans.labels_))\n",
    "\n",
    "lab = kmeans.predict(reduced_data)\n",
    "\n",
    "\n",
    "cm1R = []\n",
    "\n",
    "cm2R = []\n",
    "\n",
    "cm3R = []\n",
    "\n",
    "cm4R = []\n",
    "\n",
    "# Republican Comments \n",
    "\n",
    "print(\"Repub\")\n",
    "\n",
    "for a in range(len(randIndicesR)):\n",
    "    dec = kmeans.predict(np.array((RListPolSentiment[randIndicesR[a]], \n",
    "                 RListPolAff[randIndicesR[a]])).reshape((1, -1)))\n",
    "    if dec == 0:\n",
    "        cm1R.append(Rcomments[a])\n",
    "    elif dec == 1:\n",
    "        cm2R.append(Rcomments[a])\n",
    "    elif dec == 2:\n",
    "        cm3R.append(Rcomments[a])\n",
    "    elif dec == 3:\n",
    "        cm4R.append(Rcomments[a])\n",
    "\n",
    "print(\"Democrat\")\n",
    "\n",
    "cm1D = []\n",
    "\n",
    "cm2D = []\n",
    "\n",
    "cm3D = []\n",
    "\n",
    "cm4D = []\n",
    "\n",
    "for b in range(len(randIndicesD)):\n",
    "    dec = kmeans.predict(np.array((DListSentiment[randIndicesD[b]], \n",
    "                 DListPolAff[randIndicesD[b]])).reshape((1, -1)))\n",
    "    if dec == 0:\n",
    "        cm1D.append(Dcomments[b])\n",
    "    elif dec == 1:\n",
    "        cm2D.append(Dcomments[b])\n",
    "    elif dec == 2:\n",
    "        cm3D.append(Dcomments[b])\n",
    "    elif dec == 3:\n",
    "        cm4D.append(Dcomments[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking out some of the comments based on their class Labeling reveal indicators of Bias and Sentiment as seen on the K-Means Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comments Republican\")\n",
    "print(cm1R[1])\n",
    "print()\n",
    "print(cm2R[4])\n",
    "print()\n",
    "print(cm3R[11]) #5, 6, 10 \n",
    "print()\n",
    "print(cm4R[8])\n",
    "print()\n",
    "print(\"Comments Democrat\")\n",
    "print(cm1D[1])\n",
    "print()\n",
    "print(cm2D[1])\n",
    "print()\n",
    "print(cm3D[3])\n",
    "print()\n",
    "print(cm4D[4])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
