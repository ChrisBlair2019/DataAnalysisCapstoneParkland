{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the libraries\n",
    "*To install libraries use command 'conda install -c r r-library'\n",
    "for libraries conda cant find use rstudio\n",
    "install.packages(\"wordcloud\", \"/Users/yourusernamehere/anaconda/lib/R/library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: NLP\n",
      "Loading required package: RColorBrewer\n",
      "\n",
      "Attaching package: ‘SentimentAnalysis’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    write\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"XML\")\n",
    "library(tm)\n",
    "library(wordcloud)\n",
    "library(SentimentAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we select the dataset that we want to manipulate and create subsets based off the different twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset <- read.csv('/Users/Sourav/Desktop/DataAnalysisCapstone/all.csv', header = T)\n",
    "\n",
    "datasetBBC <- subset(dataset, dataset$screen_name == \"BBCBreaking\")\n",
    "datasetBusinessweek <- subset(dataset, dataset$screen_name == \"BW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a corpus of that dataset so we can run it through the wordcloud, something interesting is the amount\n",
    "of filler words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<VCorpus>>\n",
       "Metadata:  corpus specific: 0, document level (indexed): 0\n",
       "Content:  documents: 2200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus1 = VCorpus(VectorSource(datasetBBC$tweet))\n",
    "\n",
    "corpus1\n",
    "\n",
    "wordcloud(corpus1, max.words=100, random.order = FALSE, colors=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get rid of this we can remove numbers, stopwords, or any other words that are meaningless but reoccuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in tm_map(corpus1, content_transformer(tolower)): could not find function \"tm_map\"\n",
     "output_type": "error",
     "traceback": [
      "Error in tm_map(corpus1, content_transformer(tolower)): could not find function \"tm_map\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "corpus1 <- tm_map(corpus1, content_transformer(tolower))\n",
    "corpus1 <- tm_map(corpus1, removeNumbers)\n",
    "corpus1 <- tm_map(corpus1, removeWords, stopwords(\"english\"))\n",
    "corpus1 <- tm_map(corpus1, removeWords, c(\"will\", \"like\"))\n",
    "\n",
    "wordcloud(corpus1, max.words=250, random.order = FALSE, colors=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing with a different twitter handle to see what different or similar topics these outlets are\n",
    "talking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = VCorpus(VectorSource(datasetBusinessweek$tweet))\n",
    "corpus2 <- tm_map(corpus2, content_transformer(tolower))\n",
    "corpus2 <- tm_map(corpus2, removeNumbers)\n",
    "corpus2 <- tm_map(corpus2, removeWords, stopwords(\"english\"))\n",
    "corpus2 <- tm_map(corpus2, removeWords, c(\"will\", \"like\"))\n",
    "\n",
    "wordcloud(corpus2, max.words=250, random.order = FALSE, colors=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
